{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### chan 2020/11/24\n",
    "### build a cnn for nmist classification task based on numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from layers import *\n",
    "from loss import loss_MSE, loss_CrossEntropy\n",
    "from activation import ReLU_forward, ReLU_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from temp_modules import *\n",
    "#from temp_optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义权重、神经元、梯度\n",
    "weights = {}\n",
    "weights_scale = 1e-2\n",
    "filters = 1\n",
    "fc_units=64\n",
    "weights[\"K1\"] = weights_scale * np.random.randn(1, filters, 3, 3).astype(np.float64)\n",
    "weights[\"b1\"] = np.zeros(filters).astype(np.float64)\n",
    "weights[\"W2\"] = weights_scale * np.random.randn(filters * 13 * 13, fc_units).astype(np.float64)\n",
    "weights[\"b2\"] = np.zeros(fc_units).astype(np.float64)\n",
    "weights[\"W3\"] = weights_scale * np.random.randn(fc_units, 10).astype(np.float64)\n",
    "weights[\"b3\"] = np.zeros(10).astype(np.float64)\n",
    "\n",
    "# 初始化神经元和梯度\n",
    "nuerons={}\n",
    "gradients={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义前向传播\n",
    "def forward(X):\n",
    "    nuerons[\"conv1\"]=conv_forward(X.astype(np.float64),weights[\"K1\"],weights[\"b1\"])\n",
    "    #print(nuerons[\"conv1\"].shape)\n",
    "    nuerons[\"conv1_relu\"]=ReLU_forward(nuerons[\"conv1\"])\n",
    "    #print(nuerons[\"conv1_relu\"].shape)\n",
    "    nuerons[\"maxp1\"]=pooling_max_forward(nuerons[\"conv1_relu\"].astype(np.float64),poolKernel=(2,2))\n",
    "    #print(nuerons[\"maxp1\"].shape)\n",
    "\n",
    "    nuerons[\"flatten\"]=flatten_forward(nuerons[\"maxp1\"])\n",
    "    #print(nuerons[\"flatten\"].shape)\n",
    "    \n",
    "    nuerons[\"fc2\"]=fc_forward(nuerons[\"flatten\"],weights[\"W2\"],weights[\"b2\"])\n",
    "    #print(nuerons[\"fc2\"].shape)\n",
    "    nuerons[\"fc2_relu\"]=ReLU_forward(nuerons[\"fc2\"])\n",
    "    #print(nuerons[\"fc2_relu\"].shape)\n",
    "    nuerons[\"y\"]=fc_forward(nuerons[\"fc2_relu\"],weights[\"W3\"],weights[\"b3\"])\n",
    "    #print(nuerons[\"y\"].shape)\n",
    "\n",
    "    return nuerons[\"y\"]\n",
    "\n",
    "# 定义反向传播\n",
    "def backward(X,y_true):\n",
    "    #print('backward')\n",
    "    loss,dy=loss_CrossEntropy(nuerons[\"y\"],y_true)\n",
    "    #print(dy.shape)\n",
    "    gradients[\"W3\"],gradients[\"b3\"],gradients[\"fc2_relu\"]=fc_backward(dy,weights[\"W3\"],nuerons[\"fc2_relu\"])\n",
    "    #print(gradients[\"fc2_relu\"].shape)\n",
    "    gradients[\"fc2\"]=ReLU_backward(gradients[\"fc2_relu\"],nuerons[\"fc2\"])\n",
    "    #print(gradients[\"fc2\"].shape)\n",
    "    gradients[\"W2\"],gradients[\"b2\"],gradients[\"flatten\"]=fc_backward(gradients[\"fc2\"],weights[\"W2\"],nuerons[\"flatten\"])\n",
    "    #print(gradients[\"flatten\"].shape)\n",
    "    gradients[\"maxp1\"]=flatten_backward(gradients[\"flatten\"],nuerons[\"maxp1\"])\n",
    "    #print(gradients[\"maxp1\"].shape)\n",
    "    gradients[\"conv1_relu\"]=pooling_max_backward(gradients[\"maxp1\"].astype(np.float64),nuerons[\"conv1_relu\"].astype(np.float64),poolKernel=(2,2))\n",
    "    #print(gradients[\"conv1_relu\"].shape)\n",
    "    gradients[\"conv1\"]=ReLU_backward(gradients[\"conv1_relu\"],nuerons[\"conv1\"])\n",
    "    #print(gradients[\"conv1\"].shape)\n",
    "    #print(weights[\"K1\"].shape)\n",
    "    #print(X.shape)\n",
    "    gradients[\"K1\"],gradients[\"b1\"],_=conv_backward(gradients[\"conv1\"],weights[\"K1\"],X)\n",
    "    #print('check...')\n",
    "    #print(gradients[\"K1\"].shape)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temp_load_mnist import load_mnist_datasets\n",
    "from temp_utils import to_categorical\n",
    "train_set, val_set, test_set = load_mnist_datasets('mnist.pkl.gz')\n",
    "train_x,val_x,test_x=np.reshape(train_set[0],(-1,1,28,28)),np.reshape(val_set[0],(-1,1,28,28)),np.reshape(test_set[0],(-1,1,28,28))\n",
    "train_y,val_y,test_y=to_categorical(train_set[1]),to_categorical(val_set[1]),to_categorical(test_set[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape:(16, 1, 28, 28),y.shape:(16, 10)\n"
     ]
    }
   ],
   "source": [
    "# 随机选择训练样本\n",
    "train_num = train_x.shape[0]\n",
    "def next_batch(batch_size):\n",
    "    idx=np.random.choice(train_num,batch_size)\n",
    "    return train_x[idx],train_y[idx]\n",
    "\n",
    "x,y= next_batch(16)\n",
    "print(\"x.shape:{},y.shape:{}\".format(x.shape,y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _copy_weights_to_zeros(weights):\n",
    "    result = {}\n",
    "    result.keys()\n",
    "    for key in weights.keys():\n",
    "        result[key] = np.zeros_like(weights[key])\n",
    "    return result\n",
    "\n",
    "class SGD(object):\n",
    "    \"\"\"\n",
    "    小批量梯度下降法\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, weights, lr=0.01, momentum=0.9, decay=1e-5):\n",
    "        \"\"\"\n",
    "\n",
    "        :param weights: 权重，字典类型\n",
    "        :param lr: 初始学习率\n",
    "        :param momentum: 动量因子\n",
    "        :param decay: 学习率衰减\n",
    "        \"\"\"\n",
    "        self.v = _copy_weights_to_zeros(weights)  # 累积动量大小\n",
    "        self.iterations = 0  # 迭代次数\n",
    "        self.lr = self.init_lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.decay = decay\n",
    "\n",
    "    #def iterate(self, layers):\n",
    "    def iterate(self, gradients):\n",
    "        \"\"\"\n",
    "        迭代一次\n",
    "        :param m: 模型\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 更新学习率\n",
    "        self.lr = self.init_lr / (1 + self.iterations * self.decay)\n",
    "        \n",
    "        for key in weights.keys():\n",
    "            #self.v[key] = self.momentum * self.v[key] + self.lr * gradients[key]\n",
    "            #weights[key] -= self.v[key]\n",
    "            weights[key] = weights[key] - self.lr * gradients[key]\n",
    "            \n",
    "            \n",
    "        \n",
    "        '''\n",
    "        # 更新动量和梯度\n",
    "        for layer in layers:\n",
    "            for key in layer.weights.keys():\n",
    "                self.v[key] = self.momentum * self.v[key] + self.lr * layer.gradients[key]\n",
    "                layer.weights[key] -= self.v[key]\n",
    "        '''\n",
    "\n",
    "        # 更新迭代次数\n",
    "        self.iterations += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取精度\n",
    "def get_accuracy(X,y_true):\n",
    "    y_predict=forward(X)\n",
    "    return np.mean(np.equal(np.argmax(y_predict,axis=-1),\n",
    "                            np.argmax(y_true,axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " step:0 ; loss:9.99931237273234\n",
      " train_acc:0.5;  val_acc:0.12\n",
      "\n",
      " step:100 ; loss:8.321827419791397\n",
      " train_acc:0.0;  val_acc:0.09\n",
      "\n",
      " step:200 ; loss:8.501653935431559\n",
      " train_acc:0.0;  val_acc:0.055\n",
      "\n",
      " step:300 ; loss:8.10843869756178\n",
      " train_acc:0.0;  val_acc:0.09\n",
      "\n",
      " step:400 ; loss:7.668313177789439\n",
      " train_acc:0.0;  val_acc:0.13\n",
      "\n",
      " step:500 ; loss:2.414854949532359\n",
      " train_acc:1.0;  val_acc:0.44\n",
      "\n",
      " step:600 ; loss:2.237092409344888\n",
      " train_acc:0.5;  val_acc:0.365\n",
      "\n",
      " step:700 ; loss:3.0440249681280602\n",
      " train_acc:0.5;  val_acc:0.645\n",
      "\n",
      " step:800 ; loss:1.7848914735825891\n",
      " train_acc:1.0;  val_acc:0.71\n",
      "\n",
      " step:900 ; loss:1.2125240359629217\n",
      " train_acc:1.0;  val_acc:0.65\n",
      "\n",
      " step:1000 ; loss:1.9117553711634487\n",
      " train_acc:0.5;  val_acc:0.73\n",
      "\n",
      " step:1100 ; loss:2.3730064389762093\n",
      " train_acc:1.0;  val_acc:0.715\n",
      "\n",
      " step:1200 ; loss:1.6752918593607373\n",
      " train_acc:0.0;  val_acc:0.835\n",
      "\n",
      " step:1300 ; loss:2.032027264632596\n",
      " train_acc:1.0;  val_acc:0.725\n",
      "\n",
      " step:1400 ; loss:1.4220047564024276\n",
      " train_acc:0.5;  val_acc:0.86\n",
      "\n",
      " step:1500 ; loss:1.0081387344953816\n",
      " train_acc:0.5;  val_acc:0.86\n",
      "\n",
      " step:1600 ; loss:3.0097602393263094\n",
      " train_acc:1.0;  val_acc:0.835\n",
      "\n",
      " step:1700 ; loss:1.1301958140341681\n",
      " train_acc:0.5;  val_acc:0.76\n",
      "\n",
      " step:1800 ; loss:2.796265691716073\n",
      " train_acc:0.5;  val_acc:0.72\n",
      "\n",
      " step:1900 ; loss:1.2643807861889735\n",
      " train_acc:1.0;  val_acc:0.785\n",
      "\n",
      " final result test_acc:0.7382;  val_acc:0.7755\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "# 初始化变量\n",
    "batch_size=2\n",
    "steps = 2000\n",
    "\n",
    "# 更新梯度\n",
    "sgd=SGD(weights,lr=0.01,decay=1e-6)\n",
    "\n",
    "for s in range(steps):\n",
    "    X,y=next_batch(batch_size)\n",
    "    #print(X.shape)\n",
    "\n",
    "    # 前向过程\n",
    "    forward(X)\n",
    "    # 反向过程\n",
    "    loss=backward(X,y)\n",
    "    #print(gradients.keys())\n",
    "    #print(weights.keys())\n",
    "    #print(nuerons.keys())\n",
    "    \n",
    "    sgd.iterate(gradients)\n",
    "    # 参数更新\n",
    "\n",
    "    if s % 100 ==0:\n",
    "        print(\"\\n step:{} ; loss:{}\".format(s,loss))\n",
    "        idx=np.random.choice(len(val_x),200)\n",
    "        print(\" train_acc:{};  val_acc:{}\".format(get_accuracy(X,y),get_accuracy(val_x[idx],val_y[idx])))\n",
    "\n",
    "print(\"\\n final result test_acc:{};  val_acc:{}\".\n",
    "      format(get_accuracy(test_x,test_y),get_accuracy(val_x,val_y)))\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true:7,y_predict:7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true:1,y_predict:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true:5,y_predict:3\n"
     ]
    }
   ],
   "source": [
    "# 随机查看预测结果\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx=np.random.choice(test_x.shape[0],3)\n",
    "x,y=test_x[idx],test_y[idx]\n",
    "y_predict = forward(x)\n",
    "for i in range(3):\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.imshow(np.reshape(x[i],(28,28)))\n",
    "    plt.show()\n",
    "    print(\"y_true:{},y_predict:{}\".format(np.argmax(y[i]),np.argmax(y_predict[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
